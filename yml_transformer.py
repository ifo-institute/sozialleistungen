# -*- coding: utf-8 -*-
"""ifo-soziallleistungen-bund.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oAXAOajDqIJlFspt_ZxWcZY6c2povVgP
"""

import requests
import yaml

url = "https://raw.githubusercontent.com/ifo-institute/sozialleistungen/refs/heads/main/sozialleistungen.yml"
response = requests.get(url)
response.raise_for_status()  # Raise an exception for bad status codes
yaml_data = yaml.safe_load(response.text)

# You can now work with the loaded YAML data, for example, print it:
print(yaml_data)

def dict_depth(data):
    if isinstance(data, dict):
        return 1 + (max(map(dict_depth, data.values())) if data else 0)
    elif isinstance(data, list):
        return 0 + (max(map(dict_depth, data)) if data else 0)
    else:
        return 0

# Determine the depth of the yaml_data
depth = dict_depth(yaml_data)

# Print the depth
print(f"The depth of yaml_data is: {depth}")

import pandas as pd

normalized_data = {}

for category, sub_categories in yaml_data.items():
    for sub_category, data_list in sub_categories.items():
        # Check if data_list is a list of dictionaries with the 'leistung' key
        if isinstance(data_list, list) and all(isinstance(item, dict) and 'leistung' in item for item in data_list):
            df = pd.DataFrame(data_list)
            df['category'] = category
            df['sub_category'] = sub_category
            normalized_data[(category, sub_category)] = df
        else:
            # Handle cases where the structure is different if necessary
            print(f"Skipping {category} - {sub_category} due to unexpected structure.")

# Concatenate all DataFrames into a single DataFrame if needed
all_data_df = pd.concat(normalized_data.values(), ignore_index=True)

# Display the resulting DataFrame
display(all_data_df.head())

# Unpack 'zielgruppen' into separate columns
zielgruppen_df = all_data_df['zielgruppen'].apply(pd.Series)
zielgruppen_df.columns = [f'zielgruppe{i+1}' for i in zielgruppen_df.columns]

# Unpack and split 'themenfelder' into separate columns
# First, ensure all elements are strings before splitting
themenfelder_split = all_data_df['themenfelder'].apply(lambda x: [str(item).split('&') for item in x])
themenfelder_flat = themenfelder_split.apply(lambda x: [item.strip() for sublist in x for item in sublist])
themenfelder_df = pd.DataFrame(themenfelder_flat.tolist())
themenfelder_df.columns = [f'themenfeld{i+1}' for i in themenfelder_df.columns]


# Concatenate the new columns with the original DataFrame
all_data_df = pd.concat([all_data_df, zielgruppen_df, themenfelder_df], axis=1)

# Display the updated DataFrame
display(all_data_df.head())

import numpy as np


# Drop specific columns themenfeld3 and themenfeld4
all_data_df.drop(['themenfeld3', 'themenfeld4'], axis=1, errors='ignore', inplace=True)


# Display the updated DataFrame head
display(all_data_df.head())

# Export DataFrame to CSV
all_data_df.to_csv("sozialleistungen.csv", index=False)

# Export DataFrame to XLSX
all_data_df.to_excel("sozialleistungen.xlsx", index=False)

print("DataFrame exported to sozialleistungen.csv and sozialleistungen.xlsx")